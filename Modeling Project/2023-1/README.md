# DSL-23-1-modeling-Stable-Diffusion

### Member: 남승우, 신소연, 안세정, 정건우

## Overview

### task
> * Reverse the typical direction of a generative text-to-image model(Stable Diffusion 2.0)
>   * Create the model that can predict the text prompt with (text, image) pairs generated by Stable Diffusion 2.0
>   * Make the prediction and compare the cosine similarity with the (text, image) pairs

## Model

### BLIP-2
<img width="600" alt="drawing" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/blip2_architecture.jpg">

#### pretrained models(Colab) : blip2-flan-t5-xl

#### pretrained models(Kaggle) : blip2-opt-2.7b  - limited RAM capacity

#### Usage
```
!pip install transformers #(Colab)
from transformers import Blip2Processor, BlipForConditionalGeneration
processor = Blip2Processor.from_pretrained('Salesforce/blip-flan-t5-xl')
model = BlipForConditionalGeneration.from_pretrained('Salesforce/blip-flan-t5-xl')
```
### CLIP
<img src="https://github.com/openai/CLIP/raw/main/CLIP.png" alt="CLIP" style="max-width: 100%;">

#### pretrained models : CLIP-ViT-H-14-laion-s32B-b79k

#### Usage
```
!pip install open_clip_torch
!pip install clip-interrogator==0.6.0
model, _, preprocess = open_clip.create_model_and_transforms('ViT-H-14', pretrained = 'laion2b-s32B-b79k)
tokenizer = open_clip.get_tokenizer('ViT-H-14')
```

### Results

<img src="https://storage.googleapis.com/kagglesdsdata/competitions/45917/5024308/images/20057f34d.png?X-Goog-Algorithm=GOOG4-RSA-SHA256&amp;X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20230408%2Fauto%2Fstorage%2Fgoog4_request&amp;X-Goog-Date=20230408T053600Z&amp;X-Goog-Expires=345600&amp;X-Goog-SignedHeaders=host&amp;X-Goog-Signature=875160a856008817f13d90d142021b9c7f092b775b5810c069c44b2a66dcea5ea45eccd282c3794f23386ae068cce78a8f653183cf7c435873f396bf7940a217a60b5488cf1caa1773a13195f8670c4d5cf0d61364656b6a6d105ee2e631eecb71c39c39d9242eef06fc40ab1dca73b7e9d7a7d40e1369c1b6a76ea8ce1b1c32ab5f63377e1000f16e59294b4358ee828fbac7d80d0c66ac125df56ed6a202070a5d394001dff9ba4e6a0d7e5b702db28e35eb485b5bfccfb3acd03564cadbc05f1485a9d07d18358074ef2ab0a518d3f25c933ab7ae0a2cb95e4ee624744aab37c264d862009b96f581f858b908f769860b8670bd175dfcad3ddd77722b45d1" data-testid="preview-image" class="sc-cQJIMN cyEnMY">

- Predicted prompt : there is a picture of a circular shaped object in the middle of a pictureconcept art, conceptual art, crater, studying a hell open rift portal, abstract holescape

<img src="https://storage.googleapis.com/kagglesdsdata/competitions/45917/5024308/images/a4e1c55a9.png?X-Goog-Algorithm=GOOG4-RSA-SHA256&amp;X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20230408%2Fauto%2Fstorage%2Fgoog4_request&amp;X-Goog-Date=20230408T053600Z&amp;X-Goog-Expires=345600&amp;X-Goog-SignedHeaders=host&amp;X-Goog-Signature=8327f22f26bf96f86119a091af748c1851b4144a15979b42e7b031f5d59838394944a5b481bf9059b9aae5a2aa98e5bcdd13982ca4c8ecd1032bdac6af6fd9ddb3b237db2dae9b285e3bbd4ee4a41dc59d55d4785247d30fd8f7cbfa56e289d998ba8ebbf41a7456167c45477451c89dec66fc841c4ba075d968b123151406cb5e71065b670d048a79155341dcce182efef117d357c2ff18a3d7a5e7f401563f3d0cb7af854865bd94cac74af30dd80f6d7aaf0a56cb1de09b622f26a816bec0302e4b174a6a14e80ca2474e39591fd2d8ccc3d9ad0573abd5515694f7b55eae1568e1448c585583cf7a3c339dd918e1d2e38dfbc54f1cd371ee6c780dd615c1" data-testid="preview-image" class="sc-cQJIMN cyEnMY">

- Predicted prompt : drawing of a robot toy robot with a robot on it's sidea screenprint, art brut, ((robot)), robot cat, robot design

```
images = os.listdir('/kaggle/input/stable-diffusion-image-to-prompts/images/')
imgIds = [i.split('.')[0] for i in images]
EMBEDDING_LENGTH = 384
eIds = list(range(EMBEDDING_LENGTH))

imgId_eId = [
    '_'.join(map(str, i)) for i in zip(
        np.repeat(imgIds, EMBEDDING_LENGTH),
        np.tile(range(EMBEDDING_LENGTH), len(imgIds)))]

assert sorted(imgId_eId) == sorted(submission.imgId_eId)
ground_truth = pd.read_csv('/kaggle/input/stable-diffusion-image-to-prompts/prompts.csv')
ground_truth = pd.merge(pd.DataFrame(imgIds, columns = ['imgId']), ground_truth, 
                        on = 'imgId', how = 'left')
ground_truth_embeddings = st_model.encode(ground_truth.prompt).flatten()
gte = pd.DataFrame(
    index = imgId_eId,
    data = ground_truth_embeddings,
    columns = ['val']
).rename_axis('imgId_eId')

from scipy import spatial
vec1 = gte['val']
vec2 = submission['val']
cos_sim = 1 - spatial.distance.cosine(vec1, vec2)
print(cos_sim)
```

- Similarity with the Dataset pairs : 0.5303403735160828
## File Description

### models 
1. data
- images - example images of Stable Diffusion competition
- sample_submission.csv - example submission of the competition
- prompts.csv - prompts images are made from 
2. modules
- BLIP2_CLIP_model_c.ipynb - for Colab environment, selecting the pretrained model of BLIP2, CLIP
- BLIP2_CLIP_model_k.ipynb - for kaggle competition

### results
- submission.csv - predicted prompts from using the manipulated modules
